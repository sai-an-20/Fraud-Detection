---
title: "ML_Assignment_1"
output:
  pdf_document: default
  html_document:
    df_print: paged
---

*Intro to ML : Assignment:*


```{r, echo=FALSE, warning = FALSE, include=FALSE}
knitr::opts_chunk$set(warning = FALSE, message = FALSE) 

#tinytex::install_tinytex()

#install.packages("ISLR2")
#install.packages("GGally")
#install.packages("reshape2")
# install.packages("tree")
# install.packages("rpart")
# install.packages("rpart.plot")
# install.packages('gbm') 
# install.packages('caret')
# install.packages("maps")
# install.packages("MASS")
# install.packages("randomForest")
#install.packages('pcr')
#install.packages("pls")
#install.packages("leaps")
#install.packages(c('neuralnet','keras','tensorflow'),dependencies = T)
#install.packages("tensorflow")
# install.packages("caTools")
#install.packages("rattle")
#install.packages("RGtk2")
#install.packages("BART")
#install.packages("BayesTree")

library(BayesTree)
library(BART)
library(randomForest)
library(gbm)
library(dplyr)
library(caTools)
library(RColorBrewer)
library(tree)
library(rpart)
library(rattle)
library(tensorflow)
library(keras)
library(pcr)
library(pls)
library(randomForest)
library(MASS)
library(maps)
library(gbm)
library(caret)
library(rpart.plot)
library(ISLR2)
library(ggplot2)
library(GGally)
library(reshape2)
library(dplyr)
library(tidyverse)
library(glmnet)
library(leaps)
library(tidyverse)
library(neuralnet)
library(readr)
library(tidymodels)
library(pROC)

```

# ----------------------------------- Chapter 2 -------------------------------- #

## Question 10

## 10.a) Reading the Boston Dataset

```{r, echo=FALSE, warning = FALSE}
knitr::opts_chunk$set(warning = FALSE, message = FALSE)

Boston <- data.frame(Boston)
print("The boston dataset has been read successfully and contains 13 columns and 506 rows.")
```

## 10.b) Plotting Pairwise Scatterplots

```{r, echo=FALSE, warning = FALSE}
knitr::opts_chunk$set(warning = FALSE, message = FALSE) 

pairs(Boston, col = 'green')
```

```{r, echo=FALSE, warning = FALSE}
knitr::opts_chunk$set(warning = FALSE, message = FALSE) 

Boston_1.cor <- cor(Boston)
```


Since the plots above seem to be very cluttered, I took a correlation of all the variables and highlighted the important ones in the below pairwise plot.

```{r, echo=FALSE, warning = FALSE}
knitr::opts_chunk$set(warning = FALSE, message = FALSE) 


Bost_sub <- Boston[,c('crim', 'rad', 'indus', 'dis', 'nox', 'age', 'tax')]
pairs(Bost_sub, col = 'yellow')
```

```{r, echo=FALSE, warning = FALSE}
Boston_2.cor <- cor(Bost_sub)
```

#### Findings

1.  Among the 13 variables in the Boston housing dataset, we have 7 variables which are highly correlated with each other (corr >= |0.7|)

2.  The following variables are negatively correlated - proportion of owner-occupied units built prior to 1940 (age) with weighted mean of distances to five Boston employment centres (dis), Proportion of non-retail business acres per town (indus) with dis, nitrogen oxides concentration (parts per 10 million) (nox) with dis implying that if the nox concentration is high in an area then the employment center is far away from there

3.  The following variables are positively correlated - indus with nox, age with nox, full-value property-tax rate per $10,000 (tax) with index of accessibility to radial highways (rad) and indus,

## 10.c) Relationship with per capita crime

```{r, echo=FALSE, warning = FALSE}
knitr::opts_chunk$set(warning = FALSE, message = FALSE) 

plot(Boston$crim,col = "orange", xlab = "rad", ylab = "Crime Rate", 
   main = "crime rate vs highway accessibility")
lines(Boston$rad, col = "green")

```

```{r, echo=FALSE, warning = FALSE}
knitr::opts_chunk$set(warning = FALSE, message = FALSE) 

plot(Boston$crim,col = "orange", xlab = "tax", ylab = "Crime Rate", 
   main = "crime rate vs highway accessibility")
lines(Boston$tax, col = "black")

```

After plotting a correlation between Crime rate and all other variables, it was seen that the accessibility to radial highways and the tax rate were correlated with crime rate the highest.

From the above graphs, we notice that, as the index of accessibility increases, the crime rate also increases and the same applies to tax vs crime rate implying that a richer neighborhood has a higher crime rate

## 10.d) Census with particularly high Crime Rates, tax, ptratio

```{r, echo=FALSE, warning = FALSE}
knitr::opts_chunk$set(warning = FALSE, message = FALSE) 

#summary(Boston$crim)
boxplot(Boston$crim, ylab = "Crime Rate", col = 'violet')

#summary(Boston$tax)
boxplot(Boston$tax, ylab = "tax", col = 'pink')

#summary(Boston$ptratio)
boxplot(Boston$ptratio, ylab = "Pupil Teacher Ratio", col = 'purple')

```

i)  Crime rate - Crime rate in the suburbs ranges from almost 0 to 88 where most of the data is within 10 and the rest of them are outliers implying that there is low crime rate in most of the areas

ii) Property Tax rate - This ranges from 185 to 710 with no outliers whatsoever but with a slightly skewed data with median around 300

iii) Pupil to Teacher Ratio - the data ranges from 12 to 22. There are very few outliers below 14 indicating that there are sufficient teachers in the suburbs for each student

## 10.e) Clarks river census

```{r, echo=FALSE, warning = FALSE}
knitr::opts_chunk$set(warning = FALSE, message = FALSE) 

census <- Boston %>% group_by(chas) %>% summarise(tot_co = n())

```

Out of the 506 records, only 35 are bound by the river

## 10.f) Median of pupil to teacher ratio

```{r, echo=FALSE, warning = FALSE}
knitr::opts_chunk$set(warning = FALSE, message = FALSE) 

med_pt <- median(Boston$ptratio)
print(paste("The median of pupil to teacher ratio is :", med_pt))

```

## 10.g) Census with lowest median of owner homes

```{r, echo=FALSE, warning = FALSE}
knitr::opts_chunk$set(warning = FALSE, message = FALSE) 

low_med <- min(Boston$medv)
low_med_census <- Boston %>% filter(medv == low_med)
print(low_med_census)

```

Comparing these records with the overall data, we see that the following features are higher than the average values of the columns: 
crime rate 
nox
age
rad
tax
lstat
ptratio

Based on this, we can imply that these 2 census tracts are not the ideal places to live in

## 10.h) More than 7 rooms per dwelling

```{r, echo=FALSE, warning = FALSE}
knitr::opts_chunk$set(warning = FALSE, message = FALSE) 

rooms_7 <- Boston %>% filter(rm > 7)
rooms_8 <- Boston %>% filter(rm > 8)

print(paste("The number of census tractswith more than 7 rooms is :", nrow(rooms_7)))
print(paste("The number of census tractswith more than 8 rooms is :", nrow(rooms_8)))

#summary(rooms_8)

```

There are 64 census tracts with more than 7 rooms and 13 census tracts with more than 8 rooms. The rooms with average greater than 8 have a low crime rate, similar ptratio as the overall group and and a low property tax implying that they are good options to be considered for living. 

# ----------------------------------- Chapter 3 ---------------------------------- #

## Question 15

## 15.a) Predicting Crime rate using all Predictors individually

```{r, echo=FALSE, warning = FALSE}
knitr::opts_chunk$set(warning = FALSE, message = FALSE) 

lr_zn = lm(crim~zn, data = Boston)
#summary(lr_zn)

print("the residulas with of zn vs crime rate are as follows:")

res = resid(lr_zn)
plot(Boston$crim, res, ylab="Residuals", xlab="zn", col = 'darkblue') 


```

```{r, echo=FALSE, warning = FALSE}
knitr::opts_chunk$set(warning = FALSE, message = FALSE) 

lr_ind = lm(crim~indus, data = Boston)
#summary(lr_ind)

print("the residulas with of indus vs crime rate are as follows:")

res = resid(lr_ind)
plot(Boston$crim, res, ylab="Residuals", xlab="indus", col = 'darkblue') 

```

```{r, echo=FALSE, warning = FALSE}
knitr::opts_chunk$set(warning = FALSE, message = FALSE) 

lr_chas = lm(crim~chas, data = Boston)
#summary(lr_chas)
print("the residulas with of chas vs crime rate are as follows:")

res = resid(lr_chas)
plot(Boston$crim, res, ylab="Residuals", xlab="chas", col = 'darkblue')

```

```{r, echo=FALSE, warning = FALSE}
knitr::opts_chunk$set(warning = FALSE, message = FALSE) 

lr_nox = lm(crim~nox, data = Boston)
#summary(lr_nox)

print("the residulas with of nox vs crime rate are as follows:")

res = resid(lr_nox)
plot(Boston$crim, res, ylab="Residuals", xlab="nox", col = 'darkblue')

```

```{r, echo=FALSE, warning = FALSE}
knitr::opts_chunk$set(warning = FALSE, message = FALSE)

lr_rm = lm(crim~rm, data = Boston)
#summary(lr_rm)
print("the residulas with of rm vs crime rate are as follows:")

res = resid(lr_rm)
plot(Boston$crim, res, ylab="Residuals", xlab="rm", col = 'darkblue')

```

```{r, echo=FALSE, warning = FALSE}
knitr::opts_chunk$set(warning = FALSE, message = FALSE) 

lr_age = lm(crim~age, data = Boston)
#summary(lr_age)
print("the residulas with of age vs crime rate are as follows:")

res = resid(lr_age)
plot(Boston$crim, res, ylab="Residuals", xlab="age", col = 'darkblue')

```

```{r, echo=FALSE, warning = FALSE}
knitr::opts_chunk$set(warning = FALSE, message = FALSE) 

lr_dis = lm(crim~dis, data = Boston)
#summary(lr_dis)
print("the residulas with of dis vs crime rate are as follows:")

res = resid(lr_dis)
plot(Boston$crim, res, ylab="Residuals", xlab="dis", col = 'darkblue')

```

```{r, echo=FALSE, warning = FALSE}
knitr::opts_chunk$set(warning = FALSE, message = FALSE) 

lr_rad = lm(crim~rad, data = Boston)
#summary(lr_rad)

print("the residulas with of rad vs crime rate are as follows:")

res = resid(lr_rad)
plot(Boston$crim, res, ylab="Residuals", xlab="rad", col = 'darkblue')

```

```{r, echo=FALSE, warning = FALSE}
knitr::opts_chunk$set(warning = FALSE, message = FALSE) 

lr_tax = lm(crim~tax, data = Boston)
#summary(lr_tax)
print("the residulas with of tax vs crime rate are as follows:")

res = resid(lr_tax)
plot(Boston$crim, res, ylab="Residuals", xlab="tax", col = 'darkblue')

```

```{r, echo=FALSE, warning = FALSE}
knitr::opts_chunk$set(warning = FALSE, message = FALSE) 

lr_ptratio = lm(crim~ptratio, data = Boston)
#summary(lr_ptratio)
print("the residulas with of ptratio vs crime rate are as follows:")

res = resid(lr_ptratio)
plot(Boston$crim, res, ylab="Residuals", xlab="ptratio", col = 'darkblue')

```

```{r, echo=FALSE, warning = FALSE}
knitr::opts_chunk$set(warning = FALSE, message = FALSE) 

lr_lstat = lm(crim~lstat, data = Boston)
#summary(lr_lstat)
print("the residulas with of lstat vs crime rate are as follows:")

res = resid(lr_lstat)
plot(Boston$crim, res, ylab="Residuals", xlab="lstat", col = 'darkblue')

```

```{r, echo=FALSE, warning = FALSE}
knitr::opts_chunk$set(warning = FALSE, message = FALSE) 

lr_medv = lm(crim~medv, data = Boston)
#summary(lr_medv)
print("the residulas with of medv vs crime rate are as follows:")

res = resid(lr_medv)
plot(Boston$crim, res, ylab="Residuals", xlab="medv", col = 'darkblue')

```

From the above analysis, we can conclude 2 things. 
1) All variables have an impact on the crime rate to different extents. Nox has the highest effect with a co-efficient of ~31 and chas has the least effect with a p value close to 0 and so can be ignored
2) None of the variables individually are strong enough to predict the crime rate by themselves

## 15.b) Multiple linear regression

```{r, echo=FALSE, warning = FALSE}
knitr::opts_chunk$set(warning = FALSE, message = FALSE) 

lr_all = lm(crim ~ ., data = Boston) 
#summary(lr_all)
print("the residulas with of all variables vs crime rate are as follows:")

res = resid(lr_all)
plot(Boston$crim, res, ylab="Residuals", xlab="all", col = 'darkblue')
 
```

The Multiple linear regression model is able to explain 44.9% of the variability in crime rate data with an error rate of 6.46. We can also notice that zn, nox, dis, rad, lstat and medv have high coefficients and hence the null hypothesis should not be rejected.

## 15.c) Comparison of individual linear regression vs multilinear regression

```{r, echo=FALSE, warning = FALSE}
knitr::opts_chunk$set(warning = FALSE, message = FALSE) 

lr_zn_cf <- lr_zn$coefficients
lr_ind_cf <- lr_ind$coefficients
lr_chas_cf <- lr_chas$coefficients
lr_nox_cf <- lr_nox$coefficients
lr_rm_cf <- lr_rm$coefficients
lr_age_cf <- lr_age$coefficients
lr_dis_cf <- lr_dis$coefficients
lr_rad_cf <- lr_rad$coefficients
lr_tax_cf <- lr_tax$coefficients
lr_ptratio_cf <- lr_ptratio$coefficients
lr_lstat_cf <- lr_lstat$coefficients
lr_medv_cf <- lr_medv$coefficients

coeffs <- data.frame(lr_zn_cf, lr_ind_cf, lr_chas_cf, lr_nox_cf, lr_rm_cf, lr_age_cf, lr_dis_cf, 
                     lr_rad_cf, lr_tax_cf, lr_ptratio_cf, lr_lstat_cf, lr_medv_cf)
coeffs <- coeffs[-1,]

colnames(coeffs) <- c('zn', 'ind', 'chas', 'nox', 'rm', 'age', 'dis', 'rad', 'tax', 'ptratio', 'lstat',
                      'medv')
row.names(coeffs) <- NULL
coeffs_t <- t(coeffs)
coeffs_t <- data.frame(coeffs_t)
coeffs_t$all <- lr_all$coefficients[-1]
colnames(coeffs_t) <- c('sing_coeff', 'mult_coeff')
plot(coeffs_t$sing_coeff, coeffs_t$mult_coeff, col = 'darkgreen')

```

Compared to the results observed earlier from individual predictors, we see that the residual cluster is closer to 0 than before in the multi linear regression model. The coefficients for the individual models and for the coefficients of the multiple linear regression model are very different. This could be because the multiple linear model considers multiple predictors to obtain the coefficient due to which the effect of one predictor over the other could be different. Whereas in the single predictor models, we have only one predictor which is used and is not validated over anything else.

## 15.d) Polynomial regression for crime rate

```{r, echo=FALSE, warning = FALSE}
knitr::opts_chunk$set(warning = FALSE, message = FALSE)

lr_zn = lm(crim~poly(zn,3), data = Boston)
#summary(lr_zn)

```

```{r, echo=FALSE, warning = FALSE}
knitr::opts_chunk$set(warning = FALSE, message = FALSE)

lr_ind = lm(crim~poly(indus,3), data = Boston)
#summary(lr_ind)

```

```{r, echo=FALSE, warning = FALSE}
knitr::opts_chunk$set(warning = FALSE, message = FALSE)

lr_nox = lm(crim~poly(nox,3), data = Boston)
#summary(lr_nox)

```

```{r, echo=FALSE, warning = FALSE}
knitr::opts_chunk$set(warning = FALSE, message = FALSE)

lr_rm = lm(crim~poly(rm,3), data = Boston)
#summary(lr_rm)

```

```{r, echo=FALSE, warning = FALSE}
knitr::opts_chunk$set(warning = FALSE, message = FALSE)

lr_age = lm(crim~poly(age,3), data = Boston)
#summary(lr_age)

```

```{r, echo=FALSE, warning = FALSE}
knitr::opts_chunk$set(warning = FALSE, message = FALSE)

lr_dis = lm(crim~poly(dis,3), data = Boston)
#summary(lr_dis)

```

```{r, echo=FALSE, warning = FALSE}
knitr::opts_chunk$set(warning = FALSE, message = FALSE)

lr_rad = lm(crim~poly(rad,3), data = Boston)
#summary(lr_rad)

```

```{r, echo=FALSE, warning = FALSE}
knitr::opts_chunk$set(warning = FALSE, message = FALSE)

lr_tax = lm(crim~poly(tax,3), data = Boston)
#summary(lr_tax)

```

```{r, echo=FALSE, warning = FALSE}
knitr::opts_chunk$set(warning = FALSE, message = FALSE)

lr_ptratio = lm(crim~poly(ptratio,3), data = Boston)
#summary(lr_ptratio)

```

```{r, echo=FALSE, warning = FALSE}
knitr::opts_chunk$set(warning = FALSE, message = FALSE)

lr_lstat = lm(crim~poly(lstat,3), data = Boston)
#summary(lr_lstat)

```

```{r, echo=FALSE, warning = FALSE}
knitr::opts_chunk$set(warning = FALSE, message = FALSE)

lr_medv = lm(crim~poly(medv,3), data = Boston)
#summary(lr_medv)

```

Indus, Nox, Age, ptratio, dis and medv have a p value less than 0.05 indicating that they could have a polynomial relationship with crime rate

# ----------------------------------- Chapter 6 -------------------------------- #

## Question 9

## 9.a) Split the data into train and test

```{r, echo=FALSE, warning = FALSE}
knitr::opts_chunk$set(warning = FALSE, message = FALSE)

college_data <- data.frame(College)

college_data$Private <- as.numeric(factor(college_data$Private))
college_data <- scale(college_data)
college_data <- data.frame(college_data)

sample_size = floor(0.8*nrow(college_data))
set.seed(77)

# randomly split data in r
picked = sample(seq_len(nrow(college_data)),size = sample_size)
college_train = college_data[picked,]
college_test = college_data[-picked,]
print(paste("Train data columns: ", ncol(college_train)))
print(paste("Train data rows: ", nrow(college_train)))
print(paste("Test data columns: ", ncol(college_test)))
print(paste("Test data rows: ", nrow(college_test)))

```
The college data has been randomly split into train and test in the 80:20 ratio. The train data has 621 rows and 18 columns whereas the test data has 156 rows and 18 columns.

## 9.b) Fit a linear model using least square

```{r, echo=FALSE, warning = FALSE}
knitr::opts_chunk$set(warning = FALSE, message = FALSE)

# Fit a linear reg model
lr_apps = lm(Apps~., data = college_train) #Create the linear regression
#summary(lr_apps) #Review the results

# Obtain test error
pred_apps <- predict(lr_apps, newdata = college_test)
pred_table <- data.frame(pred_apps)
pred_table$real_apps <- college_test$Grad.Rate

test_error <- RMSE(pred_table$pred_apps, pred_table$real_apps)
print(paste("The RMSE (scaled) obtained on the linear regression model is : ", format(round(test_error, 2),nsmall = 2)))

```

## 9.c) Fit a ridge reg model using least square

```{r, echo=FALSE, warning = FALSE}
knitr::opts_chunk$set(warning = FALSE, message = FALSE)

college_data <- data.frame(College)

college_data$Private <- as.numeric(factor(college_data$Private))
college_data <- scale(college_data)
college_data <- data.frame(college_data)

sample_size = floor(0.8*nrow(college_data))
set.seed(77)

# randomly split data in r
picked = sample(seq_len(nrow(college_data)),size = sample_size)
college_train = college_data[picked,]
college_test = college_data[-picked,]

college_train_X <- subset(college_train, select = c("Private", "Accept", "Enroll", "Top10perc", "Top25perc", "F.Undergrad", "P.Undergrad", "Outstate", "Room.Board", "Books", "Personal", "PhD", "S.F.Ratio", "perc.alumni", "Expend", "Grad.Rate"))
college_test_X <- subset(college_test, select = c("Private", "Accept", "Enroll", "Top10perc", "Top25perc", "F.Undergrad", "P.Undergrad", "Outstate", "Room.Board", "Books", "Personal", "PhD", "S.F.Ratio", "perc.alumni", "Expend", "Grad.Rate"))

x = college_train_X
y_train = college_train$Apps

x_test = as.matrix(college_test_X)
y_test = college_test$Apps

ridge_reg1 = glmnet(x, y_train, nlambda = 25, alpha = 0, family = 'gaussian', lambda = 2)
preds_ridge_1 <- predict(ridge_reg1, s = 2, newx = x_test)

ridge_reg2 = glmnet(x, y_train, nlambda = 25, alpha = 0, family = 'gaussian', lambda = 1)
preds_ridge_2 <- predict(ridge_reg2, s = 2, newx = x_test)

ridge_reg3 = glmnet(x, y_train, nlambda = 25, alpha = 0, family = 'gaussian', lambda = 0)
preds_ridge_3 <- predict(ridge_reg3, s = 2, newx = x_test)

ridge_reg4 = glmnet(x, y_train, nlambda = 25, alpha = 0, family = 'gaussian', lambda = 3)
preds_ridge_4 <- predict(ridge_reg4, s = 2, newx = x_test)

pred_table <- data.frame(preds_ridge_1)
pred_table$preds_ridge_2 <- preds_ridge_2
pred_table$preds_ridge_3 <- preds_ridge_3
pred_table$preds_ridge_4 <- preds_ridge_4

colnames(pred_table) <- c("ridge_1", "ridge_2", "ridge_3", "ridge_4")

pred_table$real_val <- college_test$Grad.Rate

RMSE1 <- RMSE(pred_table$ridge_1, pred_table$real_val)
RMSE2 <- RMSE(pred_table$ridge_2, pred_table$real_val)
RMSE3 <- RMSE(pred_table$ridge_3, pred_table$real_val)
RMSE4 <- RMSE(pred_table$ridge_4, pred_table$real_val)

print(paste("The RMSE obtained when lambda is 0 : ", format(round(RMSE3, 2),nsmall = 2)))
print(paste("The RMSE obtained when lambda is 1 : ", format(round(RMSE2, 2),nsmall = 2)))
print(paste("The RMSE obtained when lambda is 2 : ", format(round(RMSE1, 2),nsmall = 2)))
print(paste("The RMSE obtained when lambda is 3 : ", format(round(RMSE4, 2),nsmall = 2)))

```

The lambda of 3 gave the lowest RMSE among the different iterations.

## 9.d) Fit a lasso reg model using least square

```{r, echo=FALSE, warning = FALSE}
knitr::opts_chunk$set(warning = FALSE, message = FALSE)

library(glmnet)

college_data <- data.frame(College)

college_data$Private <- as.numeric(factor(college_data$Private))
college_data <- scale(college_data)
college_data <- data.frame(college_data)

sample_size = floor(0.8*nrow(college_data))
set.seed(77)

# randomly split data in r
picked = sample(seq_len(nrow(college_data)),size = sample_size)
college_train = college_data[picked,]
college_test = college_data[-picked,]

college_train_X <- subset(college_train, select = c("Private", "Accept", "Enroll", "Top10perc", "Top25perc", "F.Undergrad", "P.Undergrad", "Outstate", "Room.Board", "Books", "Personal", "PhD", "S.F.Ratio", "perc.alumni", "Expend", "Grad.Rate"))
college_test_X <- subset(college_test, select = c("Private", "Accept", "Enroll", "Top10perc", "Top25perc", "F.Undergrad", "P.Undergrad", "Outstate", "Room.Board", "Books", "Personal", "PhD", "S.F.Ratio", "perc.alumni", "Expend", "Grad.Rate"))

x = college_train_X
y_train = college_train$Apps

x_test = as.matrix(college_test_X)
y_test = college_test$Apps

ridge_reg1 = glmnet(x, y_train, nlambda = 25, alpha = 1, family = 'gaussian', lambda = 2)
preds_ridge_1 <- predict(ridge_reg1, s = 2, newx = x_test)

ridge_reg2 = glmnet(x, y_train, nlambda = 25, alpha = 1, family = 'gaussian', lambda = 1)
preds_ridge_2 <- predict(ridge_reg2, s = 2, newx = x_test)

ridge_reg3 = glmnet(x, y_train, nlambda = 25, alpha = 1, family = 'gaussian', lambda = 0)
preds_ridge_3 <- predict(ridge_reg3, s = 2, newx = x_test)

ridge_reg4 = glmnet(x, y_train, nlambda = 25, alpha = 1, family = 'gaussian', lambda = 3)
preds_ridge_4 <- predict(ridge_reg4, s = 2, newx = x_test)

pred_table <- data.frame(preds_ridge_1)
pred_table$preds_ridge_2 <- preds_ridge_2
pred_table$preds_ridge_3 <- preds_ridge_3
pred_table$preds_ridge_4 <- preds_ridge_4

colnames(pred_table) <- c("ridge_1", "ridge_2", "ridge_3", "ridge_4")

pred_table$real_val <- college_test$Grad.Rate

RMSE1 <- RMSE(pred_table$ridge_1, pred_table$real_val)
RMSE2 <- RMSE(pred_table$ridge_2, pred_table$real_val)
RMSE3 <- RMSE(pred_table$ridge_3, pred_table$real_val)
RMSE4 <- RMSE(pred_table$ridge_4, pred_table$real_val)

print(paste("The RMSE obtained when lambda is 0 : ", format(round(RMSE3, 2),nsmall = 2)))
print(paste("The RMSE obtained when lambda is 1 : ", format(round(RMSE2, 2),nsmall = 2)))
print(paste("The RMSE obtained when lambda is 2 : ", format(round(RMSE1, 2),nsmall = 2)))
print(paste("The RMSE obtained when lambda is 3 : ", format(round(RMSE4, 2),nsmall = 2)))

```

```{r, echo = FALSE, warning = FALSE}
knitr::opts_chunk$set(warning = FALSE, message = FALSE)

college_data <- data.frame(College)

college_data$Private <- as.numeric(factor(college_data$Private))
college_data <- scale(college_data)
college_data <- data.frame(college_data)

sample_size = floor(0.8*nrow(college_data))
set.seed(77)

# randomly split data in r
picked = sample(seq_len(nrow(college_data)),size = sample_size)
college_train = college_data[picked,]
college_test = college_data[-picked,]

college_train_X <- subset(college_train, select = c("Private", "Accept", "Enroll", "Top10perc", "Top25perc", "F.Undergrad", "P.Undergrad", "Outstate", "Room.Board", "Books", "Personal", "PhD", "S.F.Ratio", "perc.alumni", "Expend", "Grad.Rate"))
college_test_X <- subset(college_test, select = c("Private", "Accept", "Enroll", "Top10perc", "Top25perc", "F.Undergrad", "P.Undergrad", "Outstate", "Room.Board", "Books", "Personal", "PhD", "S.F.Ratio", "perc.alumni", "Expend", "Grad.Rate"))

train_Y = college_train$Apps
test_Y = college_test$Apps

college_train_X = as.matrix(college_train_X)
college_test_X = as.matrix(college_test_X)
train_Y = as.matrix(train_Y)
test_Y = as.matrix(test_Y)

lasso1= glmnet(x=college_train_X, y=train_Y, family = "gaussian", alpha = 1)
plot(lasso1, xvar = "lambda", label=TRUE)

lasso_predict_train = predict(lasso1, s = 0.2, newx = college_test_X) 
err <- sqrt(mean((lasso_predict_train - test_Y)^2)) 

print(paste("The RMSE obtained when lambda is 0.2 : ", format(round(err, 2),nsmall = 2)))

lasso_test = glmnet(college_test_X, test_Y, alpha = 1, lambda = 0.2)      # LASSO on test dataset
lasso_test_coef = predict(lasso_test, type = "coefficients", s = 0.2) 
#lasso_test_coef

```

On further cross validation, we get an RMSE of 0.35 using lambda of 0.2. The features that are important during this process are Accept and top10perc. All the other features have a coefficient of 0.


## 9.e) Fit a PCR model using least square

```{r, echo=FALSE, warning = FALSE}
knitr::opts_chunk$set(warning = FALSE, message = FALSE)

pcr_model <- pcr(Apps~., data = college_data, scale = TRUE, validation = "CV")
#summary(pcr_model)
validationplot(pcr_model)

pcr_pred <- predict(pcr_model, college_test, ncomp = 5)

err <- RMSE(pcr_pred, college_test$Grad.Rate)
print(paste("The RMSE obtained when ncomps is 15 : ", format(round(err, 2),nsmall = 2)))

```

## 9.f) Fit a PLS model using least square

```{r, echo=FALSE, warning = FALSE}
knitr::opts_chunk$set(warning = FALSE, message = FALSE)

pls_model <- plsr(Apps~., data = college_data, scale = TRUE, validation = "CV")
#summary(pls_model)
validationplot(pls_model)

pls_pred <- predict(pls_model, college_test, ncomp = 7)

err <- RMSE(pls_pred, college_test$Grad.Rate)
print(paste("The RMSE obtained when lambda is 7 : ", format(round(err, 2),nsmall = 2)))

```

## 9.g) Comment on results

The models have an RMSE of higher than ~1.2 across all of them. But after these many attempts, there still might be a scope for improvement as we were able to obtain an RMSE of 0.35 using lasso regression on cross validation. 


## Question 11)

## Question 11.a)

```{r, echo=FALSE, warning = FALSE}
knitr::opts_chunk$set(warning = FALSE, message = FALSE)

Boston <- data.frame(Boston)

sample_size = floor(0.8*nrow(Boston))
set.seed(50)

# randomly split data in r
picked = sample(seq_len(nrow(Boston)),size = sample_size)
B_train = Boston[picked,]
B_test = Boston[-picked,]


B_train_X <- subset(B_train, select = c("zn", "indus", "chas", "nox", "rm", "age", "dis", "rad", "tax", "ptratio", "lstat", "medv"))
B_test_X <- subset(B_test, select = c("zn", "indus", "chas", "nox", "rm", "age", "dis", "rad", "tax", "ptratio", "lstat", "medv"))

x = B_train_X
y_train = B_train$crim

x_test = as.matrix(B_test_X)
y_test = B_test$crim


#Linear Regression Model using all variables

lr_crim = lm(crim~., data = B_train) #Create the linear regression
lr_crim_preds <- predict(lr_crim, newdata = B_test)
lr_crim_preds <- data.frame(lr_crim_preds)

pred_table <- lr_crim_preds

#Ridge Reg Model with all variables
ridge_reg = glmnet(x, y_train, nlambda = 25, alpha = 0, family = 'gaussian', lambda = 3)
preds_ridge <- predict(ridge_reg, s = 2, newx = x_test)
pred_table$preds_ridge <- preds_ridge

#Lasso Reg with all variables
lasso_reg = glmnet(x, y_train, nlambda = 25, alpha = 1, family = 'gaussian', lambda = 3)
preds_lasso <- predict(lasso_reg, s = 2, newx = x_test)
pred_table$preds_lasso <- preds_lasso

### Subset Selection

# 1) backward selection

set.seed(123)
train.control <- trainControl(method = "cv", number = 10)
step.model <- train(crim ~., data = B_train,
                    method = "leapBackward", 
                    tuneGrid = data.frame(nvmax = 1:12),
                    trControl = train.control
                    )
#print(paste("backward feature selection results are as follows: ", summary(step.model$finalModel)))

#Linear Model using backward Selection variables

Boston_new <- subset(Boston, select = c("zn", "nox", "dis", "rad", "ptratio", "lstat", "medv", "crim"))
sample_size = floor(0.8*nrow(Boston))
set.seed(50)

# randomly split data in r
picked = sample(seq_len(nrow(Boston_new)),size = sample_size)
B_train = Boston_new[picked,]
B_test = Boston_new[-picked,]

B_train_X <- subset(B_train, select = c("zn", "nox", "dis", "rad", "ptratio", "lstat", "medv"))
B_test_X <- subset(B_test, select = c("zn", "nox", "dis", "rad", "ptratio", "lstat", "medv"))

x = B_train_X
y_train = B_train$crim

x_test = as.matrix(B_test_X)
y_test = B_test$crim

lr_crim_bck = lm(crim~., data = B_train) #Create the linear regression
lr_crim_preds <- predict(lr_crim_bck, newdata = B_test)
pred_table$lr_crim_preds_bck <- lr_crim_preds

#Ridge Reg Model with 7 variables
ridge_reg_bck = glmnet(x, y_train, nlambda = 25, alpha = 0, family = 'gaussian', lambda = 3)
preds_ridge <- predict(ridge_reg_bck, s = 2, newx = x_test)
pred_table$preds_ridge_bck <- preds_ridge

#Lasso Reg with 7 variables
lasso_reg_bck = glmnet(x, y_train, nlambda = 25, alpha = 1, family = 'gaussian', lambda = 3)
preds_lasso <- predict(lasso_reg_bck, s = 2, newx = x_test)
pred_table$preds_lasso_bck <- preds_lasso

pred_table$real_val <- y_test

# 2) forward selection

Boston <- data.frame(Boston)

sample_size = floor(0.8*nrow(Boston))
set.seed(50)

# randomly split data in r
picked = sample(seq_len(nrow(Boston)),size = sample_size)
B_train = Boston[picked,]
B_test = Boston[-picked,]

set.seed(123)
train.control <- trainControl(method = "cv", number = 10)
step.model <- train(crim ~., data = B_train,
                    method = "leapForward", 
                    tuneGrid = data.frame(nvmax = 1:12),
                    trControl = train.control
                    )
#print(paste("Features selected using forward feature selection are as follows: ", summary(step.model$finalModel)))

#Linear Model using forward Selection variables

Boston_new <- subset(Boston, select = c("zn", "indus","nox", "dis", "rad", "ptratio", "lstat", "medv", "crim"))

sample_size = floor(0.8*nrow(Boston))
set.seed(50)

# randomly split data in r
picked = sample(seq_len(nrow(Boston_new)),size = sample_size)
B_train = Boston_new[picked,]
B_test = Boston_new[-picked,]

B_train_X <- subset(B_train, select = c("zn", "indus","nox", "dis", "rad", "ptratio", "lstat", "medv"))
B_test_X <- subset(B_test, select = c("zn", "indus","nox", "dis", "rad", "ptratio", "lstat", "medv"))

x = B_train_X
y_train = B_train$crim

x_test = as.matrix(B_test_X)
y_test = B_test$crim

lr_crim_fwd = lm(crim~., data = B_train) #Create the linear regression
lr_crim_preds <- predict(lr_crim_fwd, newdata = B_test)
pred_table$lr_crim_preds_fwd <- lr_crim_preds

#Ridge Reg Model with 7 variables
ridge_reg_fwd = glmnet(x, y_train, nlambda = 25, alpha = 0, family = 'gaussian', lambda = 3)
preds_ridge <- predict(ridge_reg_fwd, s = 2, newx = x_test)
pred_table$preds_ridge_fwd <- preds_ridge

#Lasso Reg with 7 variables
lasso_reg_fwd = glmnet(x, y_train, nlambda = 25, alpha = 1, family = 'gaussian', lambda = 3)
preds_lasso <- predict(lasso_reg_fwd, s = 2, newx = x_test)
pred_table$preds_lasso_fwd <- preds_lasso

## PCR Method

Boston <- data.frame(Boston)

sample_size = floor(0.8*nrow(Boston))
set.seed(50)

# randomly split data in r
picked = sample(seq_len(nrow(Boston)),size = sample_size)
B_train = Boston[picked,]
B_test = Boston[-picked,]

B_train_X <- subset(B_train, select = c("zn", "indus", "chas", "nox", "rm", "age", "dis", "rad", "tax", "ptratio", "lstat", "medv"))
B_test_X <- subset(B_test, select = c("zn", "indus", "chas", "nox", "rm", "age", "dis", "rad", "tax", "ptratio", "lstat", "medv"))

x = B_train_X
y_train = B_train$crim

x_test = as.matrix(B_test_X)
y_test = B_test$crim

pcr_fit <- train(x, y_train,
                 method = 'pcr',
                 trControl = trainControl(method = 'cv', number = 10),
                 tuneGrid = expand.grid(ncomp = 1:13), 
                 preProcess = c('center', 'scale'))

pcr_res <- predict(pcr_fit, x_test)
pred_table$preds_pcr <- pcr_res

### Error Calculation

RMSE_norm_lr <- RMSE(pred_table$lr_crim_preds, pred_table$real_val)
RMSE_norm_r <- RMSE(pred_table$preds_ridge, pred_table$real_val)
RMSE_norm_l <- RMSE(pred_table$preds_lasso, pred_table$real_val)

RMSE_norm_b_lr <- RMSE(pred_table$lr_crim_preds_bck, pred_table$real_val)
RMSE_norm_b_r <- RMSE(pred_table$preds_ridge_bck, pred_table$real_val)
RMSE_norm_b_l <- RMSE(pred_table$preds_lasso_bck, pred_table$real_val)

RMSE_norm_f_lr <- RMSE(pred_table$lr_crim_preds_fwd, pred_table$real_val)
RMSE_norm_f_r <- RMSE(pred_table$preds_ridge_fwd, pred_table$real_val)
RMSE_norm_f_l <- RMSE(pred_table$preds_lasso_fwd, pred_table$real_val)

RMSE_norm_pcr <- RMSE(pred_table$preds_pcr, pred_table$real_val)

print(paste("The RMSE obtained during normal lin reg is : ", format(round(RMSE_norm_lr, 2),nsmall = 2)))
print(paste("The RMSE obtained during normal ridge is : ", format(round(RMSE_norm_r, 2),nsmall = 2)))
print(paste("The RMSE obtained during normal lasso is : ", format(round(RMSE_norm_l, 2),nsmall = 2)))
print(paste("The RMSE obtained during backward selection linear reg is : ", format(round(RMSE_norm_b_lr, ),nsmall = 2)))
print(paste("The RMSE obtained during backward selection ridge reg is : ", format(round(RMSE_norm_b_r, 2),nsmall   = 2)))
print(paste("The RMSE obtained during backward selection lasso reg is : ", format(round(RMSE_norm_b_l, 2),nsmall   = 2)))
print(paste("The RMSE obtained during forward selection linear regression is : ", format(round(RMSE_norm_b_lr, 2),nsmall = 2)))
print(paste("The RMSE obtained during forward selection ridge regression is : ", format(round(RMSE_norm_b_r, 2),nsmall = 2)))
print(paste("The RMSE obtained during forward selection lasso regression is : ", format(round(RMSE_norm_b_l, 2),nsmall = 2)))
print(paste("The RMSE obtained during PCR is : ", format(round(RMSE_norm_pcr, 2),nsmall = 2)))

```

Findings:

1)During backward feature selection, Best RMSE obtained at 7 variables which are zn, nox, dis, rad, ptratio, lstat and medv

2)During Forward feature selection, Best RMSE obtained at 8 variables which are zn, nox, dis, rad, ptratio, lstat and medv

3) PCR was done using CV with number of components ranging from 1 to 10

The above values represent the RMSE obtained using various regression models such as linear, ridge, lasso and pcr along with forward and backward feature selection methods.

## 11.b) Proposing a model that seems to fit well on my dataset

The above values are the RMSE values of various models. The first and last value are the same and the lowest among the iterations. They correspond to the Linear regression and PCR Method. The other results are obtained from Lasso, ridge and other feature selection methods along with cross validation of the same. They don't seem to be performing well compared to the simple linear regression model. 

Hence a simple multi linear regression model would suffice on this dataset to obtain the lowest error.


## 11.c) Does my chosen model involve all features in the data?

```{r, echo = FALSE, warning = FALSE}
knitr::opts_chunk$set(warning = FALSE, message = FALSE)

res = resid(lr_crim)
plot(B_train$crim, res, ylab="Residuals", xlab="All Linear_Reg", col = 'darkblue')

res = resid(lr_crim_bck)
plot(B_train$crim, res, ylab="Residuals", xlab="Back Linear_Reg", col = 'darkblue')

res = resid(lr_crim_fwd)
plot(B_train$crim, res, ylab="Residuals", xlab="Fwd Linear_Reg", col = 'darkblue')

```


My Chosen model is the Linear regression model which includes all the variables. Performing feature selection reduced the number of features from 12 to ~8 but the RMSE has also increased. 



# ----------------------------------- Chapter 8 -------------------------------- #

##Question 8

## 8.a) Split the data

I Split the data into 70:30.

```{r, echo=FALSE, warning = FALSE}
knitr::opts_chunk$set(warning = FALSE, message = FALSE)

#summary(Carseats)

Carseats_1 <- data.frame(Carseats)

set.seed(99)
n=nrow(Carseats_1)
n1=floor(n/1.42)
n2=floor(n/3.36)
ii = sample(1:n,n)
car_train = Carseats_1[ii[1:n1],]
car_test = Carseats_1[ii[n1+1:n2],]

```

## 8b) Fit a Regression tree

```{r, echo=FALSE, warning = FALSE}
knitr::opts_chunk$set(warning = FALSE, message = FALSE)

decision_tree <- rpart(Sales ~ ., data=car_train)

par(mfrow=c(1,2))

fancyRpartPlot(decision_tree, col = 'darkblue')
plotcp(decision_tree, col = 'darkblue')

train_preds <- predict(decision_tree, car_train)

train_table <- data.frame(train_preds)
train_table$train_actuals <- car_train$Sales

train_MSE <- mean((train_table$train_actuals - train_table$train_preds)^2)
print(paste("The MSE obtained for tree regression is : ", format(round(train_MSE, 2),nsmall = 2)))

```

## 8.c) Use Cross Validation to determine optimal set of values.

```{r, echo=FALSE, warning = FALSE}
knitr::opts_chunk$set(warning = FALSE, message = FALSE)

# Define a range of CP values to test
cp_values <- seq(0.001, 0.1, by = 0.001)

# Create an empty vector to store cross-validated errors
cv_errors <- rep(NA, length(cp_values))

# Perform cross-validation for each CP value
for (i in seq_along(cp_values)) {
  model <- rpart(Sales ~ ., data=car_train, method = "anova", control = rpart.control(cp = cp_values[i]))
  cv_errors[i] <- sum((predict(model, newdata = car_test) - car_test$Sales)^2)
  }

# Find the CP value with the lowest cross-validated error
optimal_cp <- cp_values[which.min(cv_errors)]

final_model <- rpart(Sales ~ ., data=car_train, method = "anova", control = rpart.control(cp = optimal_cp))
test_preds <- predict(final_model, newdata=car_test)

error <- RMSE(test_preds, car_test$Sales)^2

print(paste("The MSE obtained after cross validation is : ", format(round(error, 2),nsmall = 2)))

```

We notice that pruning in this case has not improved or made the RMSE bad.

## 8.d) Use bagging approach, obtain MSE and get important variables

```{r, echo=FALSE, warning = FALSE}
knitr::opts_chunk$set(warning = FALSE, message = FALSE)

car_test_1 <- subset(car_test, select = c("CompPrice", "Income", "Advertising", "Population", "Price", "ShelveLoc", "Age", "Education", "Urban", "US"))

rf.car <- randomForest(Sales ~ ., data=car_train, mtry = 10, ntree = 300, importance = TRUE)
pred.rf <- predict(rf.car, newdata = car_test_1)

pred_df <- data.frame(matrix(unlist(pred.rf), nrow = length(pred.rf), byrow = TRUE))
pred_df$actuals <- car_test$Sales
colnames(pred_df) <- c('preds', 'real') 
                                          
test_MSE_p <- mean((pred_df$real - pred_df$preds)^2)
print(paste("The train MSE obtained is : ", format(round(test_MSE_p, 2),nsmall = 2)))
varImpPlot(rf.car)
plot(rf.car)

```

## 8.e) Use RandomForest approach, obtain MSE and get important variables

```{r, echo=FALSE, warning = FALSE}
knitr::opts_chunk$set(warning = FALSE, message = FALSE)

car_test_1 <- subset(car_test, select = c("CompPrice", "Income", "Advertising", "Population", "Price", "ShelveLoc", "Age", "Education", "Urban", "US"))

rf.car <- randomForest(Sales ~ ., data=car_train, mtry = 4, ntree = 300, importance = TRUE)
pred.rf <- predict(rf.car, newdata = car_test_1)

pred_df <- data.frame(matrix(unlist(pred.rf), nrow = length(pred.rf), byrow = TRUE))
pred_df$actuals <- car_test$Sales
colnames(pred_df) <- c('preds', 'real') 
                                          
test_MSE_p <- mean((pred_df$real - pred_df$preds)^2)
print(paste("The train MSE obtained is : ", format(round(test_MSE_p, 2),nsmall = 2)))
varImpPlot(rf.car)
plot(rf.car)

```

Here we notice that the MSE has increased by selecting only a few columns at each split. Bagging has outperformed Random Forest here. The variables have the same level of importance in both the cases. Here I have used an m slightly higher than the threshold. But after changing it a few times, i noticed that a higher m is giving a lower MSE which is ending up with a bagging model eventually.

## 8.f) BART

```{r, echo=FALSE, warning = FALSE}
knitr::opts_chunk$set(warning = FALSE, message = FALSE)

Carseats_1 <- data.frame(Carseats)

set.seed(99)
n=nrow(Carseats_1)
n1=floor(n/1.42)
n2=floor(n/3.36)
ii = sample(1:n,n)
car_train = Carseats_1[ii[1:n1],]
car_test = Carseats_1[ii[n1+1:n2],]

X_train = car_train[ , 2:10]
Y_train = car_train[ , 1]
X_test = car_test[ , 2:10]
Y_test = car_test[ , 1]

set.seed(1)

bartfit = gbart(X_train, Y_train, x.test = X_test)

y_pred = bartfit$yhat.test.mean

mse <- mean((Y_test - y_pred)^2)
print(paste("The train MSE obtained is : ", format(round(mse, 2),nsmall = 2)))

```

## 11) Question 11

## Boosting Model

## 11.a) Create a train and test data

Successfully read the caravan data and split the data into train and test sets.

```{r, echo=FALSE, warning = FALSE}
knitr::opts_chunk$set(warning = FALSE, message = FALSE)

Caravan_1 <- data.frame(Caravan)

car_train <- head(Caravan_1, 1000)
car_test  <- tail(Caravan_1, 4822)

```

## 11b) Create a Boosting Model

```{r, echo=FALSE, warning = FALSE}
knitr::opts_chunk$set(warning = FALSE, message = FALSE)

model_gbm = gbm(Purchase ~.,
              data = car_train,
              distribution = "multinomial",
              cv.folds = 10,
              shrinkage = .01,
              n.trees = 1000,
              )
summary(model_gbm)

```

PPERSAUT is the most important variable

## 11c) Predicting on test data

```{r, echo=FALSE, warning = FALSE}
knitr::opts_chunk$set(warning = FALSE, message = FALSE)

pred_test = predict.gbm(object = model_gbm,
                   newdata = car_test,
                   type = "response")
pred_test_1 <- data.frame(pred_test)
colnames(pred_test_1) <- c("Pred_No", "Pred_Yes")
final_preds <- data.frame(pred_test_1[["Pred_Yes"]])
colnames(final_preds) <- c("Pred_Yes")
final_preds$actuals <- car_test$Purchase

final_preds$Preds <- final_preds$Pred_Yes
final_preds$Preds[final_preds$Pred_Yes <= 0.2] <- 0
final_preds$Preds[final_preds$Pred_Yes > 0.2] <- 1
final_preds$Actuals <- final_preds$actuals
final_preds$Actuals <- ifelse(final_preds$Actuals=="Yes",1,0)
final_preds$Preds <- as.integer(final_preds$Preds)
final_preds$Actuals <- as.integer(final_preds$Actuals)

final_preds$Preds <- as.factor(final_preds$Preds)
final_preds$Actuals <- as.factor(final_preds$Actuals)

cm <- confusionMatrix(data=final_preds$Preds, reference = final_preds$Actuals)
print("the confusion matrix for GBM is as given below")

cm

```


Implementing logistic Regression for the same

```{r, echo=FALSE, warning = FALSE}
knitr::opts_chunk$set(warning = FALSE, message = FALSE)

logit.car <- glm(Purchase ~ ., data = car_train, family = "binomial")
probs.test2 <- predict(logit.car, car_test, type = "response")
pred.test2 <- ifelse(probs.test2 > 0.2, 1, 0)

pred_test_2 <- data.frame(pred.test2)
pred_test_2$actual <- car_test$Purchase
pred_test_2$actual <- ifelse(pred_test_2$actual=="Yes",1,0)
pred_test_2$pred.test2 <- as.factor(pred_test_2$pred.test2)
pred_test_2$actual <- as.factor(pred_test_2$actual)

cm <- confusionMatrix(data=pred_test_2$pred.test2, reference = pred_test_2$actual)

print("the confusion matrix for logistic regression is as given below")

cm

```

The accuracy of the model in logistic regression has reduced compared to boosting.


# --------------------------------- Chapter 10 ----------------------------------- #

## Question 7


```{r, echo=FALSE, warning = FALSE}
knitr::opts_chunk$set(warning = FALSE, message = FALSE)

df <- data.frame(Default)

# Plot job occupation against the target variable
ggplot(df, aes(student, fill = default)) +
    geom_bar() +
    coord_flip()

#Convert categorical to numerical

df$default = as.numeric(factor(df$default))
df$student = as.numeric(factor(df$student))

#Split the data and plot a NN

set.seed(245)
data_rows <- floor(0.80 * nrow(df))
train_indices <- sample(c(1:nrow(df)), data_rows)
train_data <- df[train_indices,]
test_data <- df[-train_indices,]

target <- train_data$default

nn_model <- nnet::nnet(target ~ .,
                       data = train_data,
                       size = 10, # 10 units in the hidden layer
                       linout = FALSE, # Use logistic activation for output layer
                       decay = 1, # Dropout rate (adjust this value as needed)
                       maxit = 1000)

pred <- predict(nn_model, test_data)
pred <- data.frame(pred)
pred$pred[pred$pred > 0.5] <- 2
pred$pred[pred$pred <= 0.5] <- 1


pred <- as.factor(pred$pred)
real <- as.factor(test_data$default)

cm_nn <- confusionMatrix(pred, real)

print("The confusion matrix for the Neural Network model predictions are given below:")
cm_nn


```


```{r, echo=FALSE, warning = FALSE}
knitr::opts_chunk$set(warning = FALSE, message = FALSE)

### Logistic Regression

df <- data.frame(Default)

#Convert categorical to numerical

df$default = as.factor(df$default)
df$student = as.factor(df$student)

#Split the data and plot a Log Reg

set.seed(245)
data_rows <- floor(0.80 * nrow(df))
train_indices <- sample(c(1:nrow(df)), data_rows)
train_data <- df[train_indices,]
test_data <- df[-train_indices,]

model_glm = glm(default ~ . , family="binomial", data = train_data)
pred_l <- predict(model_glm, newdata = test_data, type = 'response')
pred_l <- data.frame(pred_l)
pred_l$pred_resp <- pred_l$pred_l
pred_l$pred_resp[pred_l$pred_resp > 0.4] <- 'Yes'
pred_l$pred_resp[pred_l$pred_resp <= 0.4] <- 'No'
pred_l$pred_num <- pred_l$pred_l
pred_l$pred_num[pred_l$pred_num > 0.4] <- 1
pred_l$pred_num[pred_l$pred_num <= 0.4] <- 0
pred_l$real_val <- test_data$default

pred_l$real_num[pred_l$real_val == 'Yes'] <- 1
pred_l$real_num[pred_l$real_val == 'No'] <- 0


misClasificError <- mean(pred_l$pred_num != pred_l$real_num)
print(paste('Accuracy log Reg',1-misClasificError))

roc_score=roc(pred_l$real_num, pred_l$pred_num) #AUC score
plot(roc_score ,main ="ROC curve -- Logistic Regression ")

```
From the above results we can see that the NN Model has a very high accuracy of 96.5% whereas the logistic regression model has a very low accuracy of 0.97% even with diff values of probabilities.


# ------------------------------- Beauty Pays -------------------------------- #

```{r, echo=FALSE, warning = FALSE}
knitr::opts_chunk$set(warning = FALSE, message = FALSE)

beauty <- read.csv("C://Users//Sai//OneDrive//Desktop//College_Stuff/Intro_to_ML_Stuff//Assignments//BeautyData.csv")
#summary(beauty)
```

## Question 1 - Estimate the effect of Beauty on course evaluations keeping in mind the effect of other determinants

```{r, echo=FALSE, warning = FALSE}
knitr::opts_chunk$set(warning = FALSE, message = FALSE)

all_lm <- lm(CourseEvals ~ ., data = beauty)
beauty_lm <- lm(CourseEvals ~ BeautyScore, data = beauty)

#print(summary(all_lm))
#print(summary(beauty_lm))

```

From the summary table, we see that Beauty definitely has a positive score on the course evaluations. Beauty along with other factors like female or lower has a higher role than beauty alone by itself as these factors are all negatively impacting the course evaluations making beauty have a higher positive impact.


## Question 2 - Interpreting Doctor Hamermesh statement

The above solution says that beauty definitely has a positive effect on the course evaluations. And other factors like female or non english which have a negavtive impact, give beauty a boosted score in comparison with them.

```{r, echo = FALSE, warning = FALSE}
knitr::opts_chunk$set(warning = FALSE, message = FALSE)

all_lm <- lm(CourseEvals ~ female + tenuretrack + lower + nonenglish, data = beauty)
#print(summary(all_lm))

```
After running a linear model without beautyscore and only with other features, we notice that none of the given features have a positive impact on them. This tends to imply that beauty has a high influence making us believe that people who are more beautiful tend to get better course evaluations. 

But this cannot be the only conclusion from the above analysis. Beauty could mean that the professors who have higher beauty ratings could be more confident and well spoken during their lectures. they might be able to explain the concepts better and so the students give them a better score whereas it could also mean that the students just gave a higher score to the teacher they found to be beautiful at sight irrespective of the way they teach. Hence identifying if this score means more productive or more discriminative is next to impossible.

# ------------------------------- House Pricing -------------------------------- #

```{r, echo=FALSE, warning = FALSE}
knitr::opts_chunk$set(warning = FALSE, message = FALSE)

midcity <- read.csv("C://Users//Sai//OneDrive//Desktop//College_Stuff/Intro_to_ML_Stuff//Assignments//MidCity.csv")
#summary(midcity)
```


## Question 1 - Brick Housesextra premium?

```{r, echo=FALSE, warning = FALSE}
knitr::opts_chunk$set(warning = FALSE, message = FALSE)

midcity$Nbhd_fact <- as.factor(midcity$Nbhd)
midcity <- subset(midcity, select = c("Home", "Nbhd", "Offers", "SqFt", "Brick", "Bedrooms", "Price", "Bathrooms", "Nbhd_fact"))

brick_lm <- lm(Price ~ . - Nbhd, data = midcity)
summary(brick_lm)

```

The coefficient of the Brick column is 17.3k, Houses with Brick have a premium.

## Question 2 - Neighbourhood 3 extra premium?

```{r, echo=FALSE, warning = FALSE}
knitr::opts_chunk$set(warning = FALSE, message = FALSE)

brick_lm <- lm(Price ~ . - Nbhd, data = midcity)
summary(brick_lm)

```

The coefficient of the Neighbourhood 3 column is 20681, Houses in neighbourhood 3 have a premium.

## Question 3 - Brick houses along with Neighbourhood 3 premium?

```{r, echo=FALSE, warning = FALSE}
knitr::opts_chunk$set(warning = FALSE, message = FALSE)

midcity$Brick_num <- as.numeric(factor(midcity$Brick))
new_midcity <- subset(midcity, select = c("Home", "Offers", "SqFt", "Bedrooms", "Price", "Bathrooms", "Brick_num",  "Nbhd_fact"))
brick_lm <- lm(Price ~ . + Brick_num*Nbhd_fact, data = new_midcity)
summary(brick_lm)

```

The combination of hood 3 and brick houses does have a premium of 12k. But they contribute more individually as seen from the previous questions.

## Question 4 - Combine hood 1 and hood 2 into old and hood 3 as new. 

```{r, echo=FALSE, warning = FALSE}
knitr::opts_chunk$set(warning = FALSE, message = FALSE)

midcity$n_hood <- ifelse(midcity$Nbhd == 3, 1, 0)
new_midcity <- subset(midcity, select = c("Offers", "SqFt", "Bedrooms", "Price", "Bathrooms", "n_hood"))
final_lm <- lm(Price ~ ., data = new_midcity)
summary(final_lm)

```

Doing this has improved the value of houses in neighbourhood 3.


## ------------------------------- What causes what --------------------------------##


## Qustion 1

We simply can't do a normal regression of crime vs police on a city because cities with high crime tend to hire more police as they have the incentive to do so. This makes the data very skewed and any results obtained from the analysis would not be applicable on a normal situation


## Question 2

The researchers from UPENN were able to obtain the dataset of crime vs police on a day where there was expected to be high police on a day for reason not related to crime. This was the terrorism alert day. They noticed that on the day of orange alerts or red alerts, there were extra police that were deployed in the many parts of the city in washington DC. And they compared the street crime rates on those days to the normal days. They noticed that the street crime like murder or assault also go down by 7.36 times when there are extra police on the roads thus bringing down the street crime rate irrespective of their original intention.


## Question 3

They had to control for metro ridership as well because that is also an important factor in analysing the crime rate in the city. For example, if there are less tourists or less population on the streets, it leads to lesser crime. So for the researchers to ensure that the results seen earlier was valid, they had to check the metro ridership as well. Once they did this, they found out that the average metro ridership did not changemuch on alert days compared to normal days. This implies that the population was similar to the other days and probably the only reason for low crime was high police on the roads.


## Question 4

The column one describes the crime rate on days of high alert in district 1 one where the crime drops by 2.26 times compared to normal. With high alerts on other districts, the crime rate drops only by 0.57 times. The metro ridership seems to be normal and is not affected by the alerts whatsoever. 

The conclusion being that more police on the roads lead to less street crime depending on which city the analysis is made for.

## -------------------------------- Project Contribution ----------------------------------##

My contribution to the project is listed below:

1) Dataset finalization - Went through multiple datasets on kaggle to find data that was relevant and had sufficient rows and columns for a full fledged analysis

2) Data Understanding and data Cleaning - Explained the dataset, the problem statement and the solution approach to the team and also performed data cleaning

3) Exploratory data analysis - Performed data analysis across the columns and the target and obtained many insights which was later suppoe=rted by the model used

4) Modelling - Split the data into train, validation and test and built a decision tree model and also performed cross validation to get the best optimal parameters fro tree depth and complexity. 

5) Result Interpretation - I helped the team understand the the results obtained from all of our models and gave them an idea on how the results can be presented for better understanding of the audience and also ow the results can be used by the clients for maximum profits from our model. 


# ----------------------------------- The End -------------------------------- #
